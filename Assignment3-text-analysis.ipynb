{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Personal Details:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "#!pip install wn\n",
    "#!python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Word_Net(wn_dataframe):\n",
    "    import wn\n",
    "    ####################run vactorizer to get words to replace##########\n",
    "    vector = TfidfVectorizer(min_df=0.01,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "    df_columns = vector.fit_transform(wn_dataframe[\"story\"])\n",
    "    df_columns=pd.DataFrame(df_columns.toarray(), columns=vector.get_feature_names_out())\n",
    "    print(f\"shape is:\",df_columns.shape)\n",
    "    ###################\n",
    "    print(r\"words replaced:\")\n",
    "    print(df_columns.columns)\n",
    "    wordnet_he = wn.Wordnet('omw-he:1.4')\n",
    "    for feature in df_columns.columns:#go through the features and replace them \n",
    "            w1 = wordnet_he.synsets(feature)\n",
    "            if(w1):#meaning the word exist in word_net database\n",
    "                if(w1[0].pos==\"a\" ):#if the word is adjective continue\n",
    "                    feature_lema=w1[0].lemmas()\n",
    "                    print(\"replaced\",feature,feature_lema[0])\n",
    "                    wn_dataframe[\"story\"]=wn_dataframe[\"story\"].str.replace(feature,feature_lema[0])\n",
    "                    \n",
    "    return wn_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "# !pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "# import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story gender\n",
       "0  כשחבר הזמין אותי לחול, לא באמת חשבתי שזה יקרה,...      m\n",
       "1  לפני שהתגייסתי לצבא עשיתי כל מני מיונים ליחידו...      m\n",
       "2  מאז שהתחילו הלימודים חלומו של כל סטודנט זה הפנ...      f\n",
       "3  כשהייתי ילד, מטוסים היה הדבר שהכי ריתק אותי. ב...      m\n",
       "4  ‏הייתי מדריכה בכפר נוער ומתאם הכפר היינו צריכי...      f\n",
       "5  לפני כ3 חודשים טסתי לרומא למשך שבוע. טסתי במטו...      f\n",
       "6  אני כבר שנתיים נשוי והשנה אני ואישתי סוף סוף י...      m\n",
       "7  השנה התחלנו שיפוץ בדירה שלנו בתל אביב. הדירה ה...      f"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(753, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(8)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_example_id</th>\n",
       "      <th>story</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_example_id                                              story\n",
       "0                0  כל קיץ אני והמשפחה נוסעים לארצות הברית לוס אנג...\n",
       "1                1  הגעתי לשירות המדינה אחרי שנתיים כפעיל בתנועת \"...\n",
       "2                2  אחת האהבות הגדולות שלי אלו הכלבים שלי ושל אישת..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(323, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# personal imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer #allowed from comment from https://md.hit.ac.il/mod/forum/discuss.php?d=116482\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    df_copy = df.copy(deep=True)\n",
    "    df_copy[\"story\"] = df_copy[\"story\"].apply(lambda txt: ''.join([c if (c >= 'א' and c <= 'ת') or c == ' ' else '' for c in txt]))\n",
    "    df_copy=Word_Net(df_copy)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# splitting the target data to male and female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gender(df_train):\n",
    "    X_train = df_train.drop(columns=[\"gender\"])\n",
    "    y_male = (df_train[\"gender\"] == \"m\").astype(int)\n",
    "    y_female = (df_train[\"gender\"] == \"f\").astype(int)\n",
    "\n",
    "    return X_train, y_male, y_female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculating the target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(param,model_name,dataframe,train):\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vector', vectorizer()),\n",
    "    ('model', model_name())\n",
    "        \n",
    "])\n",
    "    return dataframe,score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vector parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector_params():\n",
    "    full_vector_param=[{'max_df': 0.9, 'min_df': 0.05, 'ngram_range':(1,9),\"binary\" : False,\"normalize\" : True}\n",
    "    ,{'max_df': 0.60, 'min_df': 0.03, 'ngram_range':(1,7),\"binary\" : False,\"normalize\" : False}                   \n",
    "    ,{'max_df': 0.99, 'min_df': 0.01, 'ngram_range' : (1,2),\"binary\" : True,\"normalize\" : True}\n",
    "    ,{'max_df': 0.85, 'min_df': 0.09, 'ngram_range':(1,5),\"binary\" : True,\"normalize\" : True}\n",
    "    ,{'max_df': 0.85, 'min_df': 0.15, 'ngram_range':(1,5),\"binary\" : False,\"normalize\" : True}\n",
    "    ,{'max_df': 0.80, 'min_df': 0.39, 'ngram_range':(1,5),\"binary\" : True,\"normalize\" : True}\n",
    "    ,{'max_df': 0.90, 'min_df': 0.03, 'ngram_range':(1,5),\"binary\" : True,\"normalize\" : True}\n",
    "    ,{'max_df': 0.90, 'min_df': 0.03, 'ngram_range':(1,5),\"binary\" : True,\"normalize\" : True}\n",
    "    ,{'max_df': 0.90, 'min_df': 0.03, 'ngram_range':(1,5),\"binary\" : False,\"normalize\" : True}\n",
    "    ,{'max_df': 0.60, 'min_df': 0.03, 'ngram_range':(1,7),\"binary\" : False,\"normalize\" : True}                 \n",
    "                      ]\n",
    "    \n",
    "    \n",
    "    vec_name_list=[CountVectorizer(), TfidfVectorizer()]\n",
    "    return full_vector_param,vec_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vectorizering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectroziering(vec_params,vec_name,dataframe):\n",
    "    if(type(vec_name)==type(TfidfVectorizer())):\n",
    "        vector = TfidfVectorizer(min_df=vec_params['min_df'],max_df=vec_params['max_df'],ngram_range=vec_params['ngram_range'],binary=vec_params['binary'])\n",
    "        X_train = vector.fit_transform(dataframe[\"story\"])\n",
    "        X_train_normalized=X_train\n",
    "        if(vec_params['normalize']):\n",
    "            normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "            X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "    if(type(vec_name)==type(CountVectorizer())):\n",
    "        vector = CountVectorizer(min_df=vec_params['min_df'],max_df=vec_params['max_df'],ngram_range=vec_params['ngram_range'],binary=vec_params['binary'])\n",
    "        X_train = vector.fit_transform(dataframe[\"story\"])\n",
    "        X_train_normalized=X_train\n",
    "        if(vec_params['normalize']):\n",
    "            normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "            X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "    return vector,X_train_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_params():#dictionary that contains the arguments for each model that we used\n",
    "#LogisticRegression\n",
    "    model_param={\"LogisticRegression\" : {\n",
    "                 \n",
    "                 \"model__random_state\":[42]\n",
    "    },\n",
    "                 \"KNN\" :{\n",
    "                 \n",
    "                 \"model__n_neighbors\" : [3,4],\n",
    "                           \"model__algorithm\":[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "                           \"model__n_jobs\":[-1]\n",
    "                            \n",
    "                 },\n",
    "                          \"DecisionTreeClassifier\" : {\n",
    "                              \"model__max_depth\" : [14,12,10,8],\n",
    "                              \"model__random_state\" : [42]\n",
    "                          },\n",
    "                           \"SGDClassifier\" : {\n",
    "                               \"model__loss\":[\"hinge\",\"log_loss\",\"modified_huber\",\"squared_hinge\",\"perceptron\",\"squared_error\",\"huber\"],\n",
    "                               \"model__n_jobs\" : [-1],\n",
    "                               \"model__learning_rate\" : [\"optimal\",\"invscaling\",\"constant\",\"adaptive\"],\n",
    "                               \"model__penalty\" : [\"l1\",\"l2\",\"elasticnet\",None],\n",
    "                               \"model__alpha\" : [0.0001,0.0002,0.0003,0.0005]\n",
    "                           },\n",
    "                 \"SVC\" : {\n",
    "                     \"model__kernel\" : [\"linear\",\"poly\"]\n",
    "                     \n",
    "                 }\n",
    "                 \n",
    "                           \n",
    "                 \n",
    "                    \n",
    "                 \n",
    "                }\n",
    "    model_dict={\"LogisticRegression\":LogisticRegression(),\"KNN\":KNeighborsClassifier(),\"DecisionTreeClassifier\":DecisionTreeClassifier(),\n",
    "               \"SGDClassifier\":SGDClassifier(),\"SVC\":SVC()}\n",
    "             \n",
    "    return model_param,model_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters for the machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is: (753, 5417)\n",
      "words replaced:\n",
      "Index(['אבא', 'אבא שלי', 'אבי', 'אביב', 'אבל', 'אבל אז', 'אבל אחרי', 'אבל אין',\n",
      "       'אבל אמרתי', 'אבל אני',\n",
      "       ...\n",
      "       'תקופת', 'תקופת המבחנים', 'תקופת הקורונה', 'תקין', 'תשובה', 'תשובות',\n",
      "       'תשומת', 'תשומת לב', 'תשלום', 'תשע'],\n",
      "      dtype='object', length=5417)\n",
      "replaced אוהב אוֹהֵב\n",
      "replaced אחדים אֲחָדִים\n",
      "replaced אחר אַחֵר\n",
      "replaced אחרון אַחֲרוֹן\n",
      "replaced אסור אָסוּר\n",
      "replaced אפל אָפֵל\n",
      "replaced בא בָּא\n",
      "replaced בהול בָּהוּל\n",
      "replaced בטוח בָּטוּחַ\n",
      "replaced גדול גָּדוֹל\n",
      "replaced הגון הָגוּן\n",
      "replaced הרוס הָרוּס\n",
      "replaced זריז זָרִיז\n",
      "replaced חיובי חִיּוּבִי\n",
      "replaced חם חַם\n",
      "replaced חמישי חֲמִישִׁי\n",
      "replaced חסר חָסֵר\n",
      "replaced טעים טָעִים\n",
      "replaced יפה יָפֶה\n",
      "replaced ישראלי יִשְׂרְאֵלִי\n",
      "replaced כבד כָּבֵד\n",
      "replaced כדאי כְּדָאִי\n",
      "replaced כולל כּוֹלֵל\n",
      "replaced מבין מֵבִין\n",
      "replaced מגניב מַגְנִיב\n",
      "replaced מדעי מַדָּעִי\n",
      "replaced מהצד מֵהַצַּד\n",
      "replaced מוזר מוּזָר\n",
      "replaced מידי מִיָּדִי\n",
      "replaced מינוס מִינוּס\n",
      "replaced מכסף מֻכְסָף\n",
      "replaced מלא מָלֵא\n",
      "replaced מלאה מְעַיֵּף\n",
      "replaced מפתיע מַפְתִּיעַ\n",
      "replaced מקרה מְקֹרֶה\n",
      "replaced מרגש מֻרְגָּשׁ\n",
      "replaced מרשים מַרְשִׁים\n",
      "replaced משמעותי מַשְׁמָעוּתִי\n",
      "replaced מתאים מַתְאִים\n",
      "replaced מתלקח מִתְלַקֵּחַ\n",
      "replaced סביר סָבִיר\n",
      "replaced עדין עָדִין\n",
      "replaced עדיף עָדִיף\n",
      "replaced עובר עוֹבֵר\n",
      "replaced עורג עוֹרֵג\n",
      "replaced עלי עִלִּי\n",
      "replaced עמוס עָמוּס\n",
      "replaced צפוף צָפוּף\n",
      "replaced קודם קוֹדֵם\n",
      "replaced קל קַל\n",
      "replaced קר קַר\n",
      "replaced קשה קָשֶׁה\n",
      "replaced קשור קָשׁוּר\n",
      "replaced רב רַב\n",
      "replaced רביעי רְבִיעִי\n",
      "replaced רגיל רָגִיל\n",
      "replaced רוטיני רוּטִינִי\n",
      "replaced רחב רָחָב\n",
      "replaced רע רַע\n",
      "replaced רפואי רְפוּאִי\n",
      "replaced שבע שָׂבֵעַ\n",
      "replaced שונה שׁוֹנֶה\n",
      "replaced שכן שָׁכֵן\n",
      "replaced שלילי שְׁלִילִי\n",
      "replaced שעבר שֶׁעָבַר\n",
      "shape is: (323, 5337)\n",
      "words replaced:\n",
      "Index(['אבא', 'אבא שלי', 'אבוד', 'אבי', 'אביא', 'אביב', 'אבל', 'אבל אז',\n",
      "       'אבל אני', 'אבל אף',\n",
      "       ...\n",
      "       'תקופה ארוכה', 'תקופת', 'תקופת המבחנים', 'תקופת הקורונה', 'תקין',\n",
      "       'תשובה', 'תשובות', 'תשומת', 'תשומת הלב', 'תשלום'],\n",
      "      dtype='object', length=5337)\n",
      "replaced אוהב אוֹהֵב\n",
      "replaced אחדים אֲחָדִים\n",
      "replaced אחר אַחֵר\n",
      "replaced אחרון אַחֲרוֹן\n",
      "replaced אסור אָסוּר\n",
      "replaced אפל אָפֵל\n",
      "replaced בא בָּא\n",
      "replaced בטוח בָּטוּחַ\n",
      "replaced גדול גָּדוֹל\n",
      "replaced הגון הָגוּן\n",
      "replaced הרוס הָרוּס\n",
      "replaced זמני זְמַנִּי\n",
      "replaced זריז זָרִיז\n",
      "replaced חיובי חִיּוּבִי\n",
      "replaced חם חַם\n",
      "replaced חמור חָמוּר\n",
      "replaced חמישי חֲמִישִׁי\n",
      "replaced חסר חָסֵר\n",
      "replaced טעים טָעִים\n",
      "replaced יפה יָפֶה\n",
      "replaced ישראלי יִשְׂרְאֵלִי\n",
      "replaced כבד כָּבֵד\n",
      "replaced כדאי כְּדָאִי\n",
      "replaced כולל כּוֹלֵל\n",
      "replaced מבין מֵבִין\n",
      "replaced מגניב מַגְנִיב\n",
      "replaced מדעי מַדָּעִי\n",
      "replaced מהצד מֵהַצַּד\n",
      "replaced מוזר מוּזָר\n",
      "replaced מידי מִיָּדִי\n",
      "replaced מכסף מֻכְסָף\n",
      "replaced מלא מָלֵא\n",
      "replaced מלאה מְעַיֵּף\n",
      "replaced מפתיע מַפְתִּיעַ\n",
      "replaced מקרה מְקֹרֶה\n",
      "replaced מרגש מֻרְגָּשׁ\n",
      "replaced מרשים מַרְשִׁים\n",
      "replaced משמעותי מַשְׁמָעוּתִי\n",
      "replaced משעמם מְשַׁעֲמֵם\n",
      "replaced מתאים מַתְאִים\n",
      "replaced מתלקח מִתְלַקֵּחַ\n",
      "replaced עדיף עָדִיף\n",
      "replaced עובר עוֹבֵר\n",
      "replaced עורג עוֹרֵג\n",
      "replaced עלי עִלִּי\n",
      "replaced עמוס עָמוּס\n",
      "replaced קודם קוֹדֵם\n",
      "replaced קל קַל\n",
      "replaced קר קַר\n",
      "replaced קשה קָשֶׁה\n",
      "replaced קשור קָשׁוּר\n",
      "replaced רב רַב\n",
      "replaced רביעי רְבִיעִי\n",
      "replaced רגיל רָגִיל\n",
      "replaced רוטיני רוּטִינִי\n",
      "replaced רע רַע\n",
      "replaced רפואי רְפוּאִי\n",
      "replaced שבע שָׂבֵעַ\n",
      "replaced שונה שׁוֹנֶה\n",
      "replaced שכן שָׁכֵן\n",
      "replaced שעבר שֶׁעָבַר\n",
      "male best score: 0.6436567487090015\n",
      "female best score: 0.6436567487090015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5661744839445167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5743096355695612\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6692041623928916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.48536664767804166\n",
      "male best score: 0.6401585500976346\n",
      "female best score: 0.6401585500976346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5995339858345975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5791251505207932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.681637163932794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.49622625339420534\n",
      "male best score: nan\n",
      "female best score: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.6299771389299051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5196597332943813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.6163119379875871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6571230682680497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.6331939075245481\n",
      "male best score: nan\n",
      "female best score: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5894785963962595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.6089430388625983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6847625489752851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5163966203145671\n",
      "male best score: 0.49739146356185754\n",
      "female best score: 0.49739146356185754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.6001373399211001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5820210125791292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6964714654219841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.47148936429895033\n",
      "male best score: 0.49739146356185754\n",
      "female best score: 0.49739146356185754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.6369471646751683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.6011657508404866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.70662548754468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.49208548236930383\n",
      "male best score: 0.6153182822309444\n",
      "female best score: 0.6153182822309444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5623110859634555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5206910284711854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6168228249779875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.48196622269744005\n",
      "male best score: 0.618676435032087\n",
      "female best score: 0.618676435032087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5258637705102904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5206752131636903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6135766933838949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.4758672086767947\n",
      "male best score: 0.5841426484575775\n",
      "female best score: 0.5841426484575775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4437362581051529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5583494398813426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5288502003931868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.5976748326166064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5203780319038225\n",
      "male best score: 0.5923979869528138\n",
      "female best score: 0.5923979869528138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4493248564667285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5502857055355383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5479703511598357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.5963078460622988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5056520967912218\n",
      "male best score: 0.47360997862685783\n",
      "female best score: 0.47360997862685783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5166100708657413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5406249363371225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.5227573489502486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5104720659189892\n",
      "male best score: 0.47195959775341106\n",
      "female best score: 0.47195959775341106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5337580697709017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5574877275229728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.5286269880764924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5035195721699378\n",
      "male best score: 0.6573433502093078\n",
      "female best score: 0.6573433502093078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5874109463917301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5925679296678121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6699385741981998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.4694311624677473\n",
      "male best score: 0.6514036197827868\n",
      "female best score: 0.6514036197827868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.596916686412668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.586005449144031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.677878429388993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.533047626796374\n",
      "male best score: 0.6573433502093078\n",
      "female best score: 0.6573433502093078\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5874109463917301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5925679296678121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6735520775704156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.4694311624677473\n",
      "male best score: 0.6514036197827868\n",
      "female best score: 0.6514036197827868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.596916686412668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.586005449144031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6838974763777571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.533047626796374\n",
      "male best score: 0.6760367652744302\n",
      "female best score: 0.6760367652744302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5585887464874112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5648746789575947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6807472136793739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.47688036899087916\n",
      "male best score: 0.6581711476214709\n",
      "female best score: 0.6581711476214709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5905351683660105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5964900371697472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6906335050311843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5145733034109798\n",
      "male best score: 0.6586304137468453\n",
      "female best score: 0.6586304137468453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.43856648065210513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5467404406736653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.5606632340329181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6745670722207533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.46598140344145156\n",
      "male best score: 0.6554103022222113\n",
      "female best score: 0.6554103022222113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', LogisticRegression())]),\n",
       "             n_jobs=-1, param_grid={'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for LogisticRegression is:0.4329778822905296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', KNeighborsClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__algorithm': ['auto', 'ball_tree', 'kd_tree',\n",
       "                                              'brute'],\n",
       "                         'model__n_jobs': [-1], 'model__n_neighbors': [3, 4]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for KNN is:0.5894785963962595\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__max_depth': [14, 12, 10, 8],\n",
       "                         'model__random_state': [42]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for DecisionTreeClassifier is:0.6089430388625983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SGDClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'model__alpha': [0.0001, 0.0002, 0.0003, 0.0005],\n",
       "                         'model__learning_rate': ['optimal', 'invscaling',\n",
       "                                                  'constant', 'adaptive'],\n",
       "                         'model__loss': ['hinge', 'log_loss', 'modified_huber',\n",
       "                                         'squared_hinge', 'perceptron',\n",
       "                                         'squared_error', 'huber'],\n",
       "                         'model__n_jobs': [-1],\n",
       "                         'model__penalty': ['l1', 'l2', 'elasticnet', None]},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SGDClassifier is:0.6935259834953293\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Pipeline(steps=[('model', SVC())]), n_jobs=-1,\n",
       "             param_grid={'model__kernel': ['linear', 'poly']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the score for SVC is:0.5163966203145671\n",
      "total best score is:0.70662548754468\n",
      "total best parm for model is:{'model__alpha': 0.0002, 'model__learning_rate': 'optimal', 'model__loss': 'perceptron', 'model__n_jobs': -1, 'model__penalty': 'elasticnet'}\n",
      "total best parm for vector isTfidfVectorizer() with vectorizer:{'max_df': 0.99, 'min_df': 0.01, 'ngram_range': (1, 2), 'binary': True, 'normalize': True}\n"
     ]
    }
   ],
   "source": [
    "df_train = clean_text(df_train)\n",
    "df_test = clean_text(df_test)\n",
    "df_train[\"story\"].to_csv('Xclean.csv', index=False,encoding='utf-8-sig')\n",
    "df_test[\"story\"].to_csv('Yclean.csv', index=False,encoding='utf-8-sig')\n",
    "X_train, y_male, y_female = split_gender(df_train.copy())\n",
    "vec_list_param,vec_name_list=load_vector_params()\n",
    "model_param,model_dict=load_model_params()\n",
    "best_score=0\n",
    "score=0\n",
    "best_parm=None\n",
    "best_vec_parm=None\n",
    "best_vectorizer=None\n",
    "best_vector=None\n",
    "for vec_params in vec_list_param:\n",
    "    for vec_name in vec_name_list:\n",
    "        vector,dataframe_vectorized=vectroziering(vec_params,vec_name,X_train)\n",
    "        \n",
    "        ##############################calculating#####################################\n",
    "        #gussian:\n",
    "        model=GaussianNB()\n",
    "        male_score = cross_val_score(model, dataframe_vectorized,y_male , cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "        print(f\"male best score:\",male_score.mean())\n",
    "        female_score=cross_val_score(model, dataframe_vectorized,y_female, cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "        print(f\"female best score:\",female_score.mean())\n",
    "        #logic regression##########\n",
    "        \n",
    "        for model_name,model in model_dict.items() :\n",
    "            P_model=Pipeline([('model', model)])\n",
    "            grid_search = GridSearchCV(estimator=P_model, param_grid=model_param[model_name], cv=10, n_jobs=-1,\n",
    "                               scoring=make_scorer(f1_score, average='macro'))\n",
    "            grid_search.fit(dataframe_vectorized,y_female)\n",
    "            score=grid_search.best_score_+score\n",
    "            grid_search.fit(dataframe_vectorized,y_male)\n",
    "            score=grid_search.best_score_+score\n",
    "            score=score/2\n",
    "            print(f\"the score for {model_name} is:{score}\")\n",
    "            if(best_score<score):\n",
    "                best_score=score\n",
    "                best_parm=grid_search.best_params_\n",
    "                best_grid_search=grid_search\n",
    "                best_estimator=best_model = grid_search.best_estimator_\n",
    "                best_vectorizer=vec_params\n",
    "                best_vec_parm=vec_name\n",
    "                best_model_name=model_name\n",
    "                best_dataframe_vectorized=dataframe_vectorized\n",
    "                best_vector=vector\n",
    "            score=0\n",
    "            \n",
    "            \n",
    "print(f\"total best score is:{best_score}\")\n",
    "print(f\"total best parm for model is:{best_parm}\")\n",
    "print(f\"total best parm for vector is{best_vec_parm} with vectorizer:{best_vectorizer}\")\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=df_test.copy(deep=True)\n",
    "X_train=best_dataframe_vectorized.copy(deep=True)\n",
    "vector,X_Test_Vectorized=vectroziering(best_vectorizer,best_vec_parm,X_test)\n",
    "columns = set(X_Test_Vectorized.columns).intersection(best_dataframe_vectorized.columns)#get the common columns in both dfs\n",
    "X_Test_Vectorized=X_Test_Vectorized[columns]\n",
    "X_train=X_train[columns]\n",
    "model=best_estimator.fit(X_train,y_male)\n",
    "y_pred=model.predict(X_Test_Vectorized)#set as np array\n",
    "y_pred=pd.Series(['m' if pred == 1 else 'f' for pred in y_pred])\n",
    "df_predicted=pd.concat([X_test['test_example_id'], y_pred], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# below are  different ways to go through the project that i tried\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # failed attempt at wordnet\n",
    "#the idea was to use only words that wordnet recongnizes,it works but prediction is low"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "import wn\n",
    "####################run vactorizer to get words to replace##########\n",
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(f\"shape is:\",X_train_normalized.shape)\n",
    "###################\n",
    "print(r\"words replaced:\")\n",
    "wordnet_he = wn.Wordnet('omw-he:1.4')\n",
    "for feature in X_train_normalized.columns.unique():\n",
    "        w1 = wordnet_he.synsets(feature)\n",
    "        if(w1):\n",
    "            if(w1[0].pos==\"a\" ):\n",
    "                feature_lema=w1[0].lemmas()\n",
    "                print(\"replaced\",feature,feature_lema[0])\n",
    "                df_train[\"story\"]=df_train[\"story\"].str.replace(feature,feature_lema[0])\n",
    "        else:\n",
    "            X_train_normalized=X_train_normalized.drop(feature,axis=1)\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'vector__min_df': [ 0.027, 0.03,0.033],\n",
    "    'vector__max_df': [0.9, 0.95],\n",
    "    'vector__ngram_range': [(1, 5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l1\",\"l2\"],\n",
    "}\n",
    "model=GaussianNB()\n",
    "pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('normalize', preprocessing.Normalizer()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, n_jobs=-1,\n",
    "                           scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "# Print the best parameters and best score found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def calculate(param,model_name,dataframe_male,dataframe_female):\n",
    "    \n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "    ('vector', vectorizer()),\n",
    "    ('normalize', preprocessing.Normalizer()),\n",
    "    ('model', model())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# old data cleaning -works but is longer and less efficient"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#df_train[\"story\"]=df_train[\"story\"].str.replace(\".\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\",\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace('\"', \"\")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\"'\", \"\")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\"?\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\"(\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\")\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\"–\", \" \")\n",
    "df_train[\"story\"]=df_train[\"story\"].str.replace(\"!\", \"\")\n",
    "label_encoder = LabelEncoder()\n",
    "df_train['gender'] = label_encoder.fit_transform(df_train['gender'])\n",
    "df_train_for_char=df_train.copy(deep=True)\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'\\s+',' ', story))#mini function-replace 1+ spaces with 1 space\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'^\\w\\s', '', story))\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r' +', ' ', story))\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'\\b .\\b', ' ', story))#replace space and period with space\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'\\b. \\b', ' ', story))#replace period and space with space\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'\\b, \\b', ' ', story))\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'\\d+', ' ', story))#replace numbers\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:re.sub(r'[^\\w\\s]', ' ', story))#replace numbers\n",
    "df_train[\"story\"]=df_train[\"story\"].apply(lambda story:story.strip())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logic regression with pipeline and searchgridcv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'vector__min_df': [ 0.027, 0.03,0.033],\n",
    "    'vector__max_df': [0.9, 0.95],\n",
    "    'vector__ngram_range': [(1, 5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l1\",\"l2\"],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, n_jobs=-1,\n",
    "                           scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "# Print the best parameters and best score found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'vector__min_df': [ 0.027, 0.03,0.033],\n",
    "    'vector__max_df': [0.9, 0.95],\n",
    "    'vector__ngram_range': [(1, 5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l1\",\"l2\"],\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('normalize', preprocessing.Normalizer()),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, n_jobs=-1,\n",
    "                           scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "# Print the best parameters and best score found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neutral network with pipeline and searchgridcv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'vector__min_df': [0.03],\n",
    "    'vector__max_df': [0.9],\n",
    "    'vector__ngram_range': [(1,5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l2\"],\n",
    "    \"model__hidden_layer_sizes\" : [(16,8)]\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('normalize', preprocessing.Normalizer()),\n",
    "    ('model', MLPClassifier(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, n_jobs=-1,\n",
    "                           scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "# Print the best parameters and best score found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "param_grid = {\n",
    "    'vector__min_df': [ 0.027, 0.03,0.033],\n",
    "    'vector__max_df': [0.9, 0.95],\n",
    "    'vector__ngram_range': [(1, 5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l1\",\"l2\"],\n",
    "}\n",
    "model=GaussianNB()\n",
    "pipeline = Pipeline([\n",
    "    ('vector', CountVectorizer()),\n",
    "    ('normalize', preprocessing.Normalizer()),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=10, n_jobs=-1,\n",
    "                           scoring=make_scorer(f1_score, average='macro'))\n",
    "\n",
    "# Fit the GridSearchCV to your data\n",
    "grid_search.fit(df_train[\"story\"], df_train[\"gender\"])\n",
    "\n",
    "# Print the best parameters and best score found by GridSearchCV\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# param_grid = {\n",
    "    'vector__min_df': [ 0.027, 0.03,0.033],\n",
    "    'vector__max_df': [0.9, 0.95],\n",
    "    'vector__ngram_range': [(1, 5)],\n",
    "    'vector__analyzer' : [\"char\",\"word\"],\n",
    "    'normalize__norm' : [\"l1\",\"l2\"],\n",
    "    \"model__hidden_layer_sizes\" : [(16,8),(32,16)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**knn model**  \n",
    "\n",
    "limited max features to 1000\n",
    "\n",
    "normalized to l2\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "idea change the vectorizer to only words that wordnet knows (drop the column in vactorizer dataframe)\n",
    "add MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy for testing#"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.50,ngram_range=(1,9),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = CountVectorizer(min_df=0.06,max_df=0.7,ngram_range=(3,8),analyzer=\"char\")\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.1,max_df=0.6,ngram_range=(3,8),stop_words=[\" \"],analyzer=\"char\",max_features=10000)\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)\n",
    "#sublinear_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#preprocessing\n",
    "vector = CountVectorizer(max_features=1000)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(X_train.toarray(), columns=vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#classifier\n",
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(3,25):#tests from 3 neighbors to 150 with cross validation of 10\n",
    "    model=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **knn model**\n",
    " \n",
    "min_df=0.1(ignore terms that appear less than 5%)\n",
    "\n",
    "max df=0.6 (ignore terms that appear more than 60%)\n",
    "\n",
    "ngram=1 to 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = CountVectorizer(min_df=0.1,max_df=0.6,ngram_range=(1,3),stop_words=[\"את\"])\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(3,25):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **knn model**\n",
    "so far this has the best score of 0.6123324178656229\n",
    "\n",
    "analysing as char\n",
    " \n",
    "min_df=0.1(ignore terms that appear less than 10%)\n",
    "\n",
    "max df=0.6 (ignore terms that appear more than 60%)\n",
    "\n",
    "ngram=3 to 8 (words that are in length 3 charchers to 8 charchers)\n",
    "\n",
    "stop_words=\" \" (space) (this addition stop words doesnt change the score in this case i kept it)\n",
    "\n",
    "max_features=10000(unrelevent since amount of features at this setting are  ~8k,will keep it anyway)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = CountVectorizer(min_df=0.1,max_df=0.6,ngram_range=(3,8),analyzer=\"char\",max_features=10000)\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(3,25):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **knn model**\n",
    " \n",
    "min_df=0.1(ignore terms that appear less than 10%)\n",
    "\n",
    "max df=0.6 (ignore terms that appear more than 60%)\n",
    "\n",
    "ngram=1 to 3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.1,max_df=0.6,ngram_range=(3,8),stop_words=[\" \"],analyzer=\"char\",max_features=10000)\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(3,25):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Gaussian Naive Bayes**\n",
    "\n",
    "**char**\n",
    "\n",
    "ngram=(3,6)\n",
    "\n",
    "analyser=char we are analysing words from 3 to 6 chars long\n",
    "\n",
    "min_df=0.05 feature must be present at atleast 5% of the stories\n",
    "\n",
    "max_df=0.7 feature must not be present at >=80% of stories\n",
    "\n",
    "stop_words=\" \" (space) this time it does matter\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.1,max_df=0.5,ngram_range=(1,9),analyzer=\"char\",binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = CountVectorizer(min_df=0.1,max_df=0.5,ngram_range=(1,9),analyzer=\"char\",binary=True)\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Gaussian Naive Bayes**\n",
    "\n",
    "ngram=(2,4)\n",
    "\n",
    "analyser=word we are analysing ngrams from 3 to 6 chars long\n",
    "\n",
    "min_df=0.1 feature must be present at atleast 10% of the stories\n",
    "\n",
    "max_df=0.8 feature must not be present at >=80% of stories\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = CountVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5))\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.50,ngram_range=(1,9),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model=GaussianNB()\n",
    "best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro')) \n",
    "print(best_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **decision tree**\n",
    "takes a very long time to process and gets ~0.6 score\n",
    "wont do alot of tests for it"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,15):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=DecisionTreeClassifier(max_depth=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.05,max_df=0.7,ngram_range=(1,5))\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,10):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=DecisionTreeClassifier(max_depth=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.15,max_df=0.95,ngram_range=(3,8),analyzer=\"char\")\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,10):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=DecisionTreeClassifier(max_depth=k)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGDClassifier \n",
    "\n",
    "mostly used for linear but works on catagorical target values too\n",
    "it calculate the sum of residual depending on intercept and find the intercept with the lowest sum of residual then put it in the formula\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.15,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,10):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=SGDClassifier(max_iter=100*k, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svc"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.05,max_df=0.95,ngram_range=(1,5))\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=SVC(kernel='linear')\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logic regression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.1,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=LogisticRegression()\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "print(f\"this is fold {k}\")\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "    best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5))\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,15):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=RandomForestClassifier(n_estimators=k, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.05,max_df=0.4,ngram_range=(1,9))\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=MLPClassifier(hidden_layer_sizes=(100,50,12), max_iter=500, random_state=42,activation=\"relu\",alpha=0.05,learning_rate=\"constant\",solver=\"adam\")\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=MLPClassifier(hidden_layer_sizes=(50), max_iter=1000, random_state=42)\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "print(f\"this is fold {k}\")\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "    best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=MLPClassifier(hidden_layer_sizes=(64,16,8), max_iter=1000, random_state=42)\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "print(f\"this is fold {k}\")\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "    best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=MLPClassifier(hidden_layer_sizes=(64,32,8), max_iter=1000, random_state=42)\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "print(f\"this is fold {k}\")\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "    best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.15,max_df=0.95,ngram_range=(3,8),analyzer=\"char\")\n",
    "X_train = vector.fit_transform(df_train_for_char[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l2\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "model=MLPClassifier(hidden_layer_sizes=(16,8), max_iter=1000, random_state=42)\n",
    "scores =  cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro'))\n",
    "print(f\"this is fold {k}\")\n",
    "if(best_score<scores.mean()):\n",
    "    best_score=scores.mean()\n",
    "    best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,15):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=LinearSVC(C=0.1*k, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vector = TfidfVectorizer(min_df=0.03,max_df=0.95,ngram_range=(1,5),binary=True)\n",
    "X_train = vector.fit_transform(df_train[\"story\"])\n",
    "normalized=preprocessing.normalize(X_train,norm=\"l1\")#can also do l2\n",
    "X_train_normalized=pd.DataFrame(normalized.toarray(), columns=vector.get_feature_names_out())\n",
    "print(X_train_normalized.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_score=0\n",
    "best_k=0\n",
    "for k in range(1,15):#tests from 3 neighbors to 25 with cross validation of 10\n",
    "    model=LinearSVC(C=0.1*k, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=\"f1_macro\") \n",
    "    print(f\"this is fold {k}\")\n",
    "    if(best_score<scores.mean()):\n",
    "        best_score=scores.mean()\n",
    "        best_k=k\n",
    "print(best_k)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier\n",
    "\n",
    "Gaussian Naive Bayes\n",
    "\n",
    "SGDClassifier\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "SVC\n",
    "\n",
    "LogisticRegression\n",
    "\n",
    "MLPClassifier\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "todo#\n",
    "*change best_score = cross_val_score(model, X_train_normalized,df_train[\"gender\"] , cv=10,scoring=make_scorer(f1_score, average='macro')) for everyone\n",
    "*input gridsearchcv\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#predict for future\n",
    "model=KNeighborsClassifier(n_neighbors=best_k)\n",
    "model.fit(X_train_normalized,df_train[\"gender\"])\n",
    "prediction=model.predict(X_train_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output to csv (optional)\n",
    "After you're done save your output to the 'classification_results.csv' csv file.<br/>\n",
    "We assume that the dataframe with your results contain the following columns:\n",
    "* column 1 (left column): 'test_example_id'  - the same id associated to each of the test stories to be predicted.\n",
    "* column 2 (right column): 'predicted_category' - the predicted gender value for each of the associated story. \n",
    "\n",
    "Assuming your predicted values are in the `df_predicted` dataframe, you should save you're results as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted.to_csv('classification_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
